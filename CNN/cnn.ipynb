{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72339b4779343e1a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import io\n",
    "import os"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-17T14:38:32.860199600Z",
     "start_time": "2024-01-17T14:38:32.843774700Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39304a3e750917da"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size is (42000, 785)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "print(f\"Training data size is {train.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T14:38:36.217757400Z",
     "start_time": "2024-01-17T14:38:34.162759200Z"
    }
   },
   "id": "34192e8b1f21cb45"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb741c85f525e362"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label size (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "X = train.drop('label', axis=1).values\n",
    "y = train['label'].values\n",
    "X = X / 255.0\n",
    "X = X.reshape(-1,28,28,1)\n",
    "y = to_categorical(y)\n",
    "\n",
    "print(f\"Label size {y.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T14:38:36.917772Z",
     "start_time": "2024-01-17T14:38:36.761044400Z"
    }
   },
   "id": "28cf5daee7be95d1"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "((37800, 28, 28, 1), (4200, 28, 28, 1), (37800, 10), (4200, 10))"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T14:38:37.973215400Z",
     "start_time": "2024-01-17T14:38:37.629716500Z"
    }
   },
   "id": "df351c7873ef9ef4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "933121fc9c066d6"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.01, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "train_gen = datagen.flow(X_train, y_train, batch_size=128)\n",
    "test_gen = datagen.flow(X_val, y_val, batch_size=128)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T14:38:39.159873Z",
     "start_time": "2024-01-17T14:38:39.076551700Z"
    }
   },
   "id": "a6b763e7d7654634"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27f91a526539bc7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Costum "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "422af0a2d6928b15"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 12, 12, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 2, 2, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 1, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 1, 1, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 692,682\n",
      "Trainable params: 691,786\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T14:38:40.498761800Z",
     "start_time": "2024-01-17T14:38:40.352286200Z"
    }
   },
   "id": "eed15d9c17ff45b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lenet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1667e0af41cd9ca"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# from keras.layers import Conv2D, AveragePooling2D\n",
    "# \n",
    "# model=Sequential()\n",
    "# model.add(Conv2D(filters=6, kernel_size=(5, 5), activation='tanh', input_shape=(28,28,1)))\n",
    "# model.add(AveragePooling2D())\n",
    "# model.add(Conv2D(filters=16, kernel_size=(5, 5), activation='tanh'))\n",
    "# model.add(AveragePooling2D())\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(units=120, activation='tanh'))\n",
    "# model.add(Dense(units=84, activation='tanh'))\n",
    "# model.add(Dense(units=10, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# \n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T14:38:41.150764600Z",
     "start_time": "2024-01-17T14:38:41.143367300Z"
    }
   },
   "id": "59fabd9b756120e5"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "train_steps = X_train.shape[0] // batch_size\n",
    "valid_steps = X_val.shape[0] // batch_size\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode=\"max\",\n",
    "        restore_best_weights=True,\n",
    "     )\n",
    "rp = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_accuracy\",\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        mode=\"max\",\n",
    "        min_lr=0.00001,\n",
    "     )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T14:38:41.952261600Z",
     "start_time": "2024-01-17T14:38:41.932036400Z"
    }
   },
   "id": "698a027e9bf773ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensorboard"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e6df342069d2f05"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "classes=[0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "  y_pred = model.predict(X_val) # Predict class probabilities as 2 => [0.1, 0, 0.9, 0, 0, 0, 0, 0, 0, 0]\n",
    "  Y_pred = np.argmax(y_pred, 1) # Decode Predicted labels\n",
    "  Y_test = np.argmax(y_val, 1) # Decode labels\n",
    "  con_mat = confusion_matrix(Y_test, Y_pred) # Confusion matrix\n",
    "\n",
    "  con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "  con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = classes,\n",
    "                     columns = classes)\n",
    "\n",
    "  figure = plt.figure(figsize=(8, 8))\n",
    "  sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  buf = io.BytesIO()\n",
    "  plt.savefig(buf, format='png')\n",
    "\n",
    "  plt.close(figure)\n",
    "  buf.seek(0)\n",
    "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "\n",
    "  image = tf.expand_dims(image, 0)\n",
    "\n",
    "  with file_writer_cm.as_default():\n",
    "    tf.summary.image(\"Confusion Matrix\", image, step=epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T14:38:43.325769500Z",
     "start_time": "2024-01-17T14:38:43.301394600Z"
    }
   },
   "id": "9a993f2eda0c9a25"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "logdir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir = logdir, histogram_freq = 1)\n",
    "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n",
    "\n",
    "# Command for starting Tensorboard\n",
    "# python -m tensorboard.main --logdir=logs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T14:38:44.027408Z",
     "start_time": "2024-01-17T14:38:44.008176300Z"
    }
   },
   "id": "2650b8801aad685f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68a3804792fbb7de"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 2s 16ms/step\n",
      "295/295 [==============================] - 69s 231ms/step - loss: 0.1620 - accuracy: 0.9491 - val_loss: 1.1363 - val_accuracy: 0.6270 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 2s 16ms/step\n",
      "295/295 [==============================] - 69s 235ms/step - loss: 0.0643 - accuracy: 0.9806 - val_loss: 0.0800 - val_accuracy: 0.9768 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 2s 16ms/step\n",
      "295/295 [==============================] - 70s 236ms/step - loss: 0.0482 - accuracy: 0.9848 - val_loss: 0.0716 - val_accuracy: 0.9761 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 2s 16ms/step\n",
      "295/295 [==============================] - 70s 238ms/step - loss: 0.0435 - accuracy: 0.9859 - val_loss: 0.0559 - val_accuracy: 0.9824 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "295/295 [==============================] - 72s 245ms/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 0.1476 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 2s 16ms/step\n",
      "295/295 [==============================] - 70s 238ms/step - loss: 0.0317 - accuracy: 0.9899 - val_loss: 0.0482 - val_accuracy: 0.9866 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "295/295 [==============================] - 70s 239ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.0360 - val_accuracy: 0.9888 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "295/295 [==============================] - 72s 243ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.0438 - val_accuracy: 0.9873 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "295/295 [==============================] - 73s 247ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0525 - val_accuracy: 0.9846 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "295/295 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9920\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 73s 247ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.0440 - val_accuracy: 0.9868 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 73s 246ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.0177 - val_accuracy: 0.9954 - lr: 2.0000e-04\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 73s 248ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0178 - val_accuracy: 0.9941 - lr: 2.0000e-04\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 74s 252ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0166 - val_accuracy: 0.9954 - lr: 2.0000e-04\n",
      "Epoch 14/100\n",
      "295/295 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9973\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 73s 247ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0137 - val_accuracy: 0.9949 - lr: 2.0000e-04\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 73s 247ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0146 - val_accuracy: 0.9956 - lr: 4.0000e-05\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "295/295 [==============================] - 73s 247ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0164 - val_accuracy: 0.9956 - lr: 4.0000e-05\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "295/295 [==============================] - 73s 248ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0149 - val_accuracy: 0.9951 - lr: 4.0000e-05\n",
      "Epoch 18/100\n",
      "295/295 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 73s 247ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0167 - val_accuracy: 0.9951 - lr: 4.0000e-05\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 73s 247ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0170 - val_accuracy: 0.9939 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 74s 250ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0168 - val_accuracy: 0.9946 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 75s 254ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0159 - val_accuracy: 0.9951 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 74s 252ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0188 - val_accuracy: 0.9944 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "295/295 [==============================] - 73s 248ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0158 - val_accuracy: 0.9949 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 73s 249ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0162 - val_accuracy: 0.9944 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "295/295 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9981Restoring model weights from the end of the best epoch: 15.\n",
      "132/132 [==============================] - 2s 18ms/step\n",
      "295/295 [==============================] - 74s 249ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.0161 - val_accuracy: 0.9944 - lr: 1.0000e-05\n",
      "Epoch 25: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation inclusive\n",
    "history = model.fit(train_gen,\n",
    "                    epochs = epochs,\n",
    "                    steps_per_epoch = train_steps,\n",
    "                    validation_data = test_gen, \n",
    "                    validation_steps = valid_steps,\n",
    "                    callbacks=[es, rp, tensorboard_callback,cm_callback])\n",
    "\n",
    "\n",
    "# Data Augmentation exclusive\n",
    "# history = model.fit(\n",
    "#     x=X_train,  # Direkte Verwendung der Trainingsdaten\n",
    "#     y=y_train,  # Direkte Verwendung der Trainingslabels\n",
    "#     epochs=epochs,\n",
    "#     batch_size=batch_size,  \n",
    "#     validation_data=(X_val, y_val),\n",
    "#     callbacks=[es, rp, tensorboard_callback, cm_callback]\n",
    "# )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T15:08:55.288598Z",
     "start_time": "2024-01-17T14:38:45.823028Z"
    }
   },
   "id": "a5c9d0c1dd18aa7"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "467a6d8532a909fc"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/trained_models/name_TFSaveFormat\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/trained_models/name_TFSaveFormat\\assets\n"
     ]
    }
   ],
   "source": [
    "# 1 - Save the full model\n",
    "model.save(\"./data/trained_models/name.h5\")\n",
    "model.save(\"./data/trained_models/name_TFSaveFormat\")\n",
    "# 2 - Save the weights of the model\n",
    "#model.save_weights(\"./data/trained_models/name_weights.h5\")\n",
    "# 3 - Save the architecture of the model\n",
    "# json_string = model.to_json()\n",
    "# with open(\"./data/trained_models/name_model.h5\", \"w\") as f:\n",
    "#     f.write(json_string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T16:01:14.789598100Z",
     "start_time": "2024-01-17T16:01:13.038601400Z"
    }
   },
   "id": "ddca61617620c15b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
